{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e951b7a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import random\n",
    "import glob\n",
    "import cv2\n",
    "import json\n",
    "import string\n",
    "import tqdm\n",
    "import numpy as np\n",
    "from imutils.perspective import four_point_transform\n",
    "from skimage import exposure\n",
    "\n",
    "from skimage.io import imread, imshow\n",
    "from skimage import img_as_ubyte\n",
    "from skimage.color import rgb2gray\n",
    "from skimage.exposure import histogram, cumulative_distribution\n",
    "from scipy.stats import cauchy, logistic\n",
    "\n",
    "import warnings\n",
    "import imutils\n",
    "from collections import Counter\n",
    "from collections import Counter\n",
    "from PIL import ImageFont, ImageDraw, Image\n",
    "from matplotlib import pyplot as plt\n",
    "import re\n",
    "import string\n",
    "from faker import Faker\n",
    "import albumentations as A\n",
    "\n",
    "from _paths import nomeroff_net_dir\n",
    "from nomeroff_net.tools.image_processing import get_cv_zone_rgb, distance\n",
    "from nomeroff_net.tools import modelhub\n",
    "from nomeroff_net.tools import modelhub\n",
    "\n",
    "warnings.simplefilter(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b7dd3210",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded model path: https://nomeroff.net.ua/datasets/autoriaNumberplateDataset-2023-02-09.zip /mnt/data/var/www/nomeroff-net/examples/ju/dataset_tools/../../../nomeroff_net/tools/../../data/./dataset/Detector/yolov8/autoriaNumberplateDataset-2023-02-09.zip\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "autoriaNumberplateDataset-2023-02-09.zip: 7.26GB [29:30, 4.10MB/s]                                \n"
     ]
    }
   ],
   "source": [
    "def visualize(image):\n",
    "    plt.figure(figsize=(20, 20))\n",
    "    plt.axis('off')\n",
    "    plt.imshow(image)\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = (20,20)\n",
    "# auto download latest dataset\n",
    "info = modelhub.download_dataset_for_model(\"yolov8\")\n",
    "PATH_TO_DATASET = info[\"dataset_path\"]\n",
    "ROOT_DIR = PATH_TO_DATASET\n",
    "dataset = \"train\"\n",
    "json_data_path = \"train/via_region_data.json\"\n",
    "\n",
    "images_formats = [\n",
    "    \"xx-transit.png\",\n",
    "]\n",
    "path_to_images_example = os.path.join(nomeroff_net_dir,\n",
    "                                      \"data/dataset/OptionsDetector/numberplate_options_example/test/img/{}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3e8b77f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "codes = [\n",
    "    \"Т0\", \"Т1\", \"Т2\", \"Т3\", \"Т4\", \"Т5\", \"Т6\", \"Т7\", \"Т8\", \"Т9\", \n",
    "    \"01\", \"02\", \"03\", \"04\", \"05\", \"06\", \"07\", \"08\", \"09\", \"10\", \"11\", \"12\", \"13\", \n",
    "    \"14\", \"15\", \"16\", \"17\", \"18\", \"19\", \"20\", \"21\", \"22\", \"23\", \"24\", \"25\", \"26\", \"27\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "cfc54ed1",
   "metadata": {},
   "outputs": [],
   "source": [
    "series = [\n",
    "#     \"AA\",\t\"BA\",\t\"CA\",\t\"EA\",\t\"HA\",\t\"IA\",\t\"KA\",\t\"MA\",\t\"OA\",\t\"PA\",\t\n",
    "#     \"TA\",\t\"XA\",\t\"AB\",\t\"BB\",\t\"CB\",\t\"EB\",\t\"HB\",\t\"IB\",\t\"KB\",\t\"MB\",\t\n",
    "#     \"OB\",\t\"PB\",\t\"TB\",\t\"XB\",\t\"AC\",\t\"BC\",\t\"CC\",\t\"EC\",\t\"HC\",\t\"IC\",\t\n",
    "#     \"KC\",\t\"MC\",\t\"OC\",\t\"PC\",\t\"TC\",\t\"XC\",\t\"AE\",\t\"BE\",\t\"CE\",\t\"EE\",\t\n",
    "#     \"HE\",\t\"IE\",\t\"KE\",\t\"ME\",\t\"OE\",\t\"PE\",\t\"TE\",\t\"XE\",\t\"AH\",\t\"BH\",\t\n",
    "#     \"CH\",\t\"EH\",\t\"HH\",\t\"IH\",\t\"KH\",\t\"MH\",\t\"OH\",\t\"PH\",\t\"TH\",\t\"XH\",\t\n",
    "#     \"AI\",\t\"BI\",\t\"CI\",\t\"EL\",\t\"HI\",\t\"II\",\t\"KI\",\t\"MI\",\t\"OI\",\t\"PI\",\t\n",
    "#     \"TI\",\t\"XI\",\t\"AK\",\t\"BK\",\t\"CK\",\t\"EK\",\t\"HK\",\t\"IK\",\t\"KK\",\t\"MK\",\t\n",
    "#     \"OK\",\t\"PK\",\t\"TK\",\t\"XK\",\t\"AM\",\t\"BM\",\t\"CM\",\t\"EM\",\t\"HM\",\t\"IM\",\t\n",
    "#     \"KM\",\t\"MM\",\t\"OM\",\t\"PM\",\t\"TM\",\t\"XM\",\t\"AO\",\t\"BO\",\t\"CO\",\t\"EO\",\t\n",
    "#     \"HO\",\t\"IO\",\t\"KO\",\t\"MO\",\t\"OO\",\t\"PO\",\t\"TO\",\t\"XO\",\t\"AP\",\t\"BP\",\t\n",
    "#     \"CP\",\t\"EP\",\t\"HP\",\t\"IP\",\t\"KP\",\t\"MP\",\t\"OP\",\t\"PP\",\t\"TP\",\t\"XP\",\t\n",
    "#     \"AT\",\t\"BT\",\t\"CT\",\t\"ET\",\t\"HT\",\t\"IT\",\t\"KT\",\t\"MT\",\t\"OT\",\t\"PT\",\t\n",
    "#     \"TT\",\t\"XT\",\t\"AX\",\t\"BX\",\t\"CX\",\t\"EX\",\t\"HX\",\t\"IX\",\t\"KX\",\t\"MX\",\t\n",
    "#     \"OX\",\t\"PX\",\t\"TX\",\t\"XX\",   \n",
    "#     \"YU\",\t\"YV\",\t\"YX\",\t\"YY\",\t\"YZ\",\n",
    "#     \"XF\",\t\"XG\",\t\"XJ\",\t\"XL\",\t\"XN\",\t\"XR\",\t\"XS\",\t\"XU\",\t\"XV\",\t\n",
    "#     \"XY\",\t\"XZ\",\t\"FF\",\t\"FG\",\t\"FJ\",\t\"FL\",\t\"FN\",\t\"FR\",\t\"FS\",\t\"FU\",\t\n",
    "#     \"FV\",\t\"FY\",\t\"FZ\",\t\"AF\",\t\"AG\",\t\"AJ\",\t\"AL\",\t\"AN\",\t\"AR\",\t\n",
    "#     \"AS\",\t\"AU\",\t\"AV\",\t\"TF\",\t\"TG\",\t\"TJ\",\t\"TL\",\t\"TN\",\t\"TR\",\t\n",
    "#     \"TS\",\t\"TU\",\t\"TV\",\t\"TY\",\t\"TZ\",\t\"ZA\",\t\"ZB\",\t\"ZC\",\t\"ZD\",\t\n",
    "#     \"ZE\",\t\"ZF\",\t\"ZG\",\t\"ZH\",\t\"ZI\",\t\"ZJ\",\t\"ZK\",\t\"ZL\",\t\"ZM\",\t\"ZN\",\t\n",
    "#     \"ZO\",\t\"ZP\",\t\"ZR\",\t\"ZS\",\t\"ZT\",\t\"ZU\",\t\"ZV\",\t\"ZX\",\t\"ZY\",\t\n",
    "#     \"ZZ\",\t\"YA\",\t\"YB\",\t\"YC\",\t\"YD\",\t\"YE\",\t\"YF\",\t\"YG\",\t\"YH\",\t\"YI\",\t\n",
    "#     \"YJ\",\t\"YK\",\t\"YL\",\t\"YM\",\t\"YN\",\t\"YO\",\t\"YP\",\t\"YR\",\t\"YS\",\t\"YT\",\t\n",
    "#     \"XW\",\t\"YW\",\t\"FW\",\t\"AW\",\t\"TW\",\t\"ZW\",\t\n",
    "      \n",
    "    \"AA\",\"AB\",\"AC\",\"AE\",\"AH\",\"AI\",\"AK\",\"AM\",\"AO\",\"AP\",\"AT\",\"AX\",\n",
    "    \"BA\",\"BB\",\"BC\",\"BE\",\"BH\",\"BI\",\"BK\",\"BM\",\"BO\",\"BT\",\"BX\",\n",
    "    \"CA\",\"CB\",\"CE\",\"CH\",\"DC\",\"DI\",\"ED\",\"HA\",\"HB\",\"HC\",\"HE\",\"HH\",\"HI\",\"HK\",\"HM\",\"HO\",\"HT\",\n",
    "    \"HX\",\"IA\",\"IB\",\"IE\",\"II\",\"KA\",\"KB\",\"KC\",\"KE\",\"KH\",\"KI\",\"KK\",\"KM\",\"KO\",\n",
    "    \"KP\",\"KT\",\"KX\",\"OO\",\"PA\",\"PD\",\"TI\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "bbab49f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "alphabet = [\n",
    "    \"A\", \"B\", \"C\", \"D\", \"E\", \"F\", \"G\", \"H\", \"I\", \"J\", \"K\", \"L\", \"M\",\n",
    "    \"N\", \"O\", \"P\", \"Q\", \"R\", \"S\", \"T\", \"U\", \"V\", \"W\", \"X\", \"Y\", \"Z\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "3130eb00",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_np_variants = []\n",
    "n = 100_000\n",
    "for i in range(n):\n",
    "    text_np = \"\"\n",
    "    \n",
    "    # add code\n",
    "    code = random.choice(codes)\n",
    "    text_np += code\n",
    "    \n",
    "    # add seria\n",
    "    seria = random.choice(series)\n",
    "    text_np += seria\n",
    "        \n",
    "    # add digits\n",
    "    for i  in range(4):\n",
    "        text_np += random.choice(string.digits)\n",
    "    \n",
    "    text_np_variants.append(text_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "79b15ca6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9167/9167 [00:00<00:00, 154728.83it/s]\n"
     ]
    }
   ],
   "source": [
    "res_datasets = {}\n",
    "res_datasets[dataset] = []\n",
    "\n",
    "with open(os.path.join(ROOT_DIR, json_data_path)) as jsonFile:\n",
    "    json_data = json.load(jsonFile)\n",
    "for key in tqdm.tqdm((json_data[\"_via_img_metadata\"])):\n",
    "    metadata = json_data[\"_via_img_metadata\"][key]\n",
    "\n",
    "    # define image_id\n",
    "    image_file_name = metadata[\"filename\"]\n",
    "    image_file_name = os.path.join(ROOT_DIR, dataset, image_file_name)\n",
    "    for region in metadata[\"regions\"]:\n",
    "        if region[\"shape_attributes\"].get(\"all_points_x\", None) is None or region[\"shape_attributes\"].get(\"all_points_y\", None) is None:\n",
    "            continue\n",
    "        np_zone = [(x, y) for x, y in zip(region[\"shape_attributes\"][\"all_points_x\"], region[\"shape_attributes\"][\"all_points_y\"])]\n",
    "        res_datasets[dataset].append([image_file_name, np_zone])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8b3be458",
   "metadata": {},
   "outputs": [],
   "source": [
    "def order_points(pts):\n",
    "    # initialzie a list of coordinates that will be ordered\n",
    "    # such that the first entry in the list is the top-left,\n",
    "    # the second entry is the top-right, the third is the\n",
    "    # bottom-right, and the fourth is the bottom-left\n",
    "    rect = np.zeros((4, 2), dtype = \"float32\")\n",
    "    # the top-left point will have the smallest sum, whereas\n",
    "    # the bottom-right point will have the largest sum\n",
    "    s = pts.sum(axis = 1)\n",
    "    rect[0] = pts[np.argmin(s)]\n",
    "    rect[2] = pts[np.argmax(s)]\n",
    "    # now, compute the difference between the points, the\n",
    "    # top-right point will have the smallest difference,\n",
    "    # whereas the bottom-left will have the largest difference\n",
    "    diff = np.diff(pts, axis = 1)\n",
    "    rect[1] = pts[np.argmin(diff)]\n",
    "    rect[3] = pts[np.argmax(diff)]\n",
    "    # return the ordered coordinates\n",
    "    return rect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5cb0b8bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_linear_cdf(image, channel, name, ax):\n",
    "    image_intensity = img_as_ubyte(image[:,:,channel])\n",
    "    freq, bins = cumulative_distribution(image_intensity)\n",
    "    target_bins = np.arange(255)\n",
    "    target_freq = np.linspace(0, 1, len(target_bins))\n",
    "    ax.step(bins, freq, c='b', label='Actual CDF')\n",
    "    ax.plot(target_bins, target_freq, c='r', label='Target CDF')\n",
    "    ax.legend()\n",
    "    ax.set_title('{} Channel: Actual vs. '\n",
    "                 'Target Cumulative Distribution'.format(name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e6621c5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_distribution(image, channel):\n",
    "    image_intensity = img_as_ubyte(image[:,:,channel])\n",
    "    freq, bins = cumulative_distribution(image_intensity)\n",
    "    target_bins = np.arange(255)\n",
    "    target_freq = np.linspace(0, 1, len(target_bins))\n",
    "    new_vals = np.interp(freq, target_freq, target_bins)\n",
    "    return new_vals[image_intensity].astype(np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7e820f19",
   "metadata": {},
   "outputs": [],
   "source": [
    "def individual_channel(image, dist, channel):\n",
    "    im_channel = img_as_ubyte(image[:,:,channel])\n",
    "    freq, bins = cumulative_distribution(im_channel)\n",
    "    new_vals = np.interp(freq, dist.cdf(np.arange(0,256)),\n",
    "                               np.arange(0,256))\n",
    "    return new_vals[im_channel].astype(np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d051b3ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def distribution(image, function, mean, std):\n",
    "    dist = function(mean, std)\n",
    "    image_intensity = img_as_ubyte(rgb2gray(image))\n",
    "    freq, bins = cumulative_distribution(image_intensity)\n",
    "    red = individual_channel(image, dist, 0)\n",
    "    green = individual_channel(image, dist, 1)\n",
    "    blue = individual_channel(image, dist, 2)\n",
    "    corrected_image = np.dstack((red, green, blue))\n",
    "    return corrected_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "56c22652",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_random_img():\n",
    "    random_i = random.randint(0, len(res_datasets[dataset]) - 1)\n",
    "    fake_img_path, fake_np_four_points = res_datasets[dataset][random_i]\n",
    "\n",
    "    fake_img = cv2.imread(fake_img_path)[:,:,::-1]\n",
    "    fake_img = np.concatenate((fake_img, 255*np.ones((*fake_img.shape[:2], 1))), axis=2)\n",
    "    ordered_p_fake = order_points(np.array(fake_np_four_points, dtype = \"float32\"))\n",
    "\n",
    "    return fake_img, ordered_p_fake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "950065c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_fake(img, fake_img, ordered_p_fake):\n",
    "\n",
    "    r1, g1, b1 = 20, 20, 20 # Original value\n",
    "    r2, g2, b2 = 20, 20, 20 # Value that we want to replace it with\n",
    "\n",
    "    red, green, blue = img[:,:,0], img[:,:,1], img[:,:,2]\n",
    "    mask = (red < r1) & (green < g1) & (blue < b1)\n",
    "    img[:,:,:3][mask] = [r2, g2, b2]\n",
    "\n",
    "    ordered_p_orig = np.array([(0, 0),\n",
    "                               (img.shape[1], 0),\n",
    "                               (img.shape[1], img.shape[0]),\n",
    "                               (0, img.shape[0])], dtype = \"float32\")\n",
    "\n",
    "\n",
    "    M = cv2.getPerspectiveTransform(ordered_p_orig,\n",
    "                                    ordered_p_fake)\n",
    "    warped = cv2.warpPerspective(img, M, (fake_img.shape[1], fake_img.shape[0]))\n",
    "    cntrs = ordered_p_fake.reshape(1, ordered_p_fake.shape[0], ordered_p_fake.shape[1]).astype(np.int32)\n",
    "\n",
    "    #print(\"warped\", img.shape, img[:,:, 0].max(), img[:,:, 1].max(), img[:,:, 2].max())\n",
    "    #print(\"warped\", img.shape, img[:,:, 0].min(), img[:,:, 1].min(), img[:,:, 2].min())\n",
    "\n",
    "    stencil = np.zeros(warped.shape).astype(warped.dtype)\n",
    "    contours = cntrs\n",
    "\n",
    "    cv2.fillPoly(stencil, contours, [255, 255, 255])\n",
    "    np_mask = cv2.bitwise_and(warped, stencil)\n",
    "\n",
    "    overlay_img1 = np.ones(fake_img.shape, np.uint8)*255\n",
    "\n",
    "    rows, cols, channels = np_mask.shape\n",
    "    overlay_img1[:, :] = warped\n",
    "    img2gray = cv2.cvtColor(overlay_img1, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    ret, mask = cv2.threshold(img2gray, 1, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "    mask_inv = cv2.bitwise_not(mask)\n",
    "\n",
    "    fake_img = fake_img.astype(np.uint8)\n",
    "    temp1 = cv2.bitwise_and(fake_img, fake_img, mask = mask_inv)\n",
    "    temp2 = cv2.bitwise_and(overlay_img1, overlay_img1, mask = mask)\n",
    "\n",
    "    temp1 = temp1.astype(np.uint8)\n",
    "    fake_np_img = cv2.add(temp1, temp2)\n",
    "    return fake_np_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cd34a8ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def domain_adoptation(src, trg, freq):\n",
    "\n",
    "    \"\"\"\n",
    "    Parameters:\n",
    "    src - source image, which style has to be changed\n",
    "    trg - target image, which low-frequency domain will be adopted\n",
    "    freq - number of frequencies to be used\n",
    "\n",
    "    Returns:\n",
    "    result - np.array based on srs image (shape and high frequencies)\n",
    "         with low frequencies of the target image\n",
    "    \"\"\"\n",
    "\n",
    "    result = np.zeros((src.shape[0],src.shape[1],src.shape[2]))\n",
    "\n",
    "    for i in range(src.shape[2]):\n",
    "        trg_fft = np.fft.fft2(trg[:,:,i])\n",
    "        src_fft = np.fft.fft2(src[:,:,i])\n",
    "\n",
    "        trg_fft_shift = np.fft.fftshift(trg_fft)\n",
    "        src_fft_shift = np.fft.fftshift(src_fft)\n",
    "\n",
    "        src_fft_shift[src.shape[0]//2-freq:src.shape[0]//2+freq,\n",
    "                         src.shape[1]//2-freq:src.shape[1]//2+freq] = \\\n",
    "            trg_fft_shift[trg.shape[0]//2-freq:trg.shape[0]//2+freq,\n",
    "                           trg.shape[1]//2-freq:trg.shape[1]//2+freq]\n",
    "\n",
    "        src_ifft_shift = np.fft.ifftshift(src_fft_shift)\n",
    "\n",
    "        result[:,:,i] = np.fft.ifft2(src_ifft_shift)\n",
    "        result[:,:,i] = np.abs(result[:,:,i])\n",
    "\n",
    "    result = np.float32(result)\n",
    "    result = cv2.cvtColor(result, cv2.COLOR_BGR2RGB)\n",
    "    result = cv2.normalize(result,None,0,1,cv2.NORM_MINMAX)\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d3684167",
   "metadata": {},
   "outputs": [],
   "source": [
    "def color_transfer(source, target):\n",
    "    source = cv2.resize(source, (target.shape[1], target.shape[0]))\n",
    "    # convert the images from the RGB to L*ab* color space, being\n",
    "    # sure to utilizing the floating point data type (note: OpenCV\n",
    "    # expects floats to be 32-bit, so use that instead of 64-bit)\n",
    "    source = cv2.cvtColor(source, cv2.COLOR_BGR2LAB).astype(\"float32\")\n",
    "    target = cv2.cvtColor(target, cv2.COLOR_BGR2LAB).astype(\"float32\")\n",
    "    # compute color statistics for the source and target images\n",
    "    (lMeanSrc, lStdSrc, aMeanSrc, aStdSrc, bMeanSrc, bStdSrc) = image_stats(source)\n",
    "    (lMeanTar, lStdTar, aMeanTar, aStdTar, bMeanTar, bStdTar) = image_stats(target)\n",
    "    # subtract the means from the target image\n",
    "    (l, a, b) = cv2.split(target)\n",
    "    l -= lMeanTar\n",
    "    a -= aMeanTar\n",
    "    b -= bMeanTar\n",
    "    # scale by the standard deviations\n",
    "    l = (lStdTar / lStdSrc) * l\n",
    "    a = (aStdTar / aStdSrc) * a\n",
    "    b = (bStdTar / bStdSrc) * b\n",
    "    # add in the source mean\n",
    "    l += lMeanSrc\n",
    "    a += aMeanSrc\n",
    "    b += bMeanSrc\n",
    "    # clip the pixel intensities to [0, 255] if they fall outside\n",
    "    # this range\n",
    "    l = np.clip(l, 0, 255)\n",
    "    a = np.clip(a, 0, 255)\n",
    "    b = np.clip(b, 0, 255)\n",
    "    # merge the channels together and convert back to the RGB color\n",
    "    # space, being sure to utilize the 8-bit unsigned integer data\n",
    "    # type\n",
    "    transfer = cv2.merge([l, a, b])\n",
    "    transfer = cv2.cvtColor(transfer.astype(\"uint8\"), cv2.COLOR_LAB2BGR)\n",
    "\n",
    "    # return the color transferred image\n",
    "    return transfer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7af06830",
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_stats(image):\n",
    "    # compute the mean and standard deviation of each channel\n",
    "    (l, a, b) = cv2.split(image)\n",
    "    (lMean, lStd) = (l.mean(), l.std())\n",
    "    (aMean, aStd) = (a.mean(), a.std())\n",
    "    (bMean, bStd) = (b.mean(), b.std())\n",
    "    # return the color statistics\n",
    "    return (lMean, lStd, aMean, aStd, bMean, bStd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7a8eff08",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_bbox(img, bbox, color=BOX_COLOR, thickness=2, **kwargs):\n",
    "    x_min, y_min, w, h = bbox\n",
    "    x_min, x_max, y_min, y_max = int(x_min), int(x_min + w), int(y_min), int(y_min + h)\n",
    "    cv2.rectangle(img, (x_min, y_min), (x_max, y_max), color=color, thickness=thickness)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f31f82a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_titles(img, bbox, title, color=BOX_COLOR, thickness=2, font_thickness = 2, font_scale=0.35, **kwargs):\n",
    "    x_min, y_min, w, h = bbox\n",
    "    x_min, x_max, y_min, y_max = int(x_min), int(x_min + w), int(y_min), int(y_min + h)\n",
    "    ((text_width, text_height), _) = cv2.getTextSize(title, cv2.FONT_HERSHEY_SIMPLEX, font_scale, font_thickness)\n",
    "    cv2.rectangle(img, (x_min, y_min - int(1.3 * text_height)), (x_min + text_width, y_min), BOX_COLOR, -1)\n",
    "    cv2.putText(img, title, (x_min, y_min - int(0.3 * text_height)), cv2.FONT_HERSHEY_SIMPLEX, font_scale, TEXT_COLOR,\n",
    "                font_thickness, lineType=cv2.LINE_AA)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "168016a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment_and_show(aug, image, filename=None,\n",
    "                     font_scale_orig=0.35, font_scale_aug=0.35, show=True, **kwargs):\n",
    "\n",
    "    augmented = aug(image=image)\n",
    "\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    image_aug = cv2.cvtColor(augmented['image'], cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    if show:\n",
    "        f, ax = plt.subplots(1, 2, figsize=(16, 8))\n",
    "        ax[0].imshow(image)\n",
    "        ax[0].set_title('Original image')\n",
    "        ax[1].imshow(image_aug)\n",
    "        ax[1].set_title('Augmented image')\n",
    "        f.tight_layout()\n",
    "\n",
    "        if filename is not None:\n",
    "            f.savefig(filename)\n",
    "\n",
    "    return augmented['image']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c5d4f02e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_in_dir(dirname):\n",
    "    return [os.path.join(dirname, fname) for fname in sorted(os.listdir(dirname))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "8e0030e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop_and_aug_numbeplate(np_img, ordered_p_fake):\n",
    "    l = np.random.uniform(0.01, 0.06)\n",
    "    random_r_crop = np.random.uniform(0.06, 0.1)\n",
    "    random_l_crop = np.random.uniform(0.01, 0.08)\n",
    "    np_img = np_img[:,:,:3].astype(np.uint8)\n",
    "    #print(np_img.shape)\n",
    "    # img_np = cv2.polylines(np_img, [ordered_p_fake.reshape((-1, 1, 2)).astype(np.int32)], True, (255, 0, 255), 2)\n",
    "\n",
    "    d_crop_l = (distance(ordered_p_fake[0], ordered_p_fake[1])+distance(ordered_p_fake[3], ordered_p_fake[3]))/2*random_l_crop\n",
    "    d_crop_r = (distance(ordered_p_fake[0], ordered_p_fake[1])+distance(ordered_p_fake[3], ordered_p_fake[3]))/2*random_r_crop\n",
    "    d2 = (distance(ordered_p_fake[1], ordered_p_fake[2])+distance(ordered_p_fake[3], ordered_p_fake[0]))/2*l\n",
    "    ordered_p_fake[0,0] += d_crop_l\n",
    "    ordered_p_fake[1,0] -= d_crop_r\n",
    "    ordered_p_fake[2,0] -= d_crop_r\n",
    "    ordered_p_fake[3,0] += d_crop_l\n",
    "\n",
    "    ordered_p_fake[1,1] -= d2\n",
    "    ordered_p_fake[2,1] += d2\n",
    "    ordered_p_fake[0,1] -= d2\n",
    "    ordered_p_fake[3,1] += d2\n",
    "    img_np = get_cv_zone_rgb(np_img, ordered_p_fake)\n",
    "\n",
    "    light = A.Compose([\n",
    "        A.RandomBrightnessContrast(p=1),\n",
    "        A.RandomGamma(p=1),\n",
    "        A.CLAHE(p=1),\n",
    "        A.Blur(),\n",
    "        A.GaussNoise(),\n",
    "        A.ShiftScaleRotate(shift_limit=0.01, scale_limit=0.01, rotate_limit=2, p=.75),\n",
    "    ], p=5)\n",
    "\n",
    "\n",
    "    # img_np = cv2.polylines(np_img, [ordered_p_fake.reshape((-1, 1, 2)).astype(np.int32)], True, (0, 255, 255), 2)\n",
    "    return augment_and_show(light, img_np, show=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "a429e1ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_fake_numberplate(img,\n",
    "                          b: int = 220 , g: int = 220, r: int = 220, a: int = 255,\n",
    "                          draw_text=True,\n",
    "                          draw_numbers=True,\n",
    "                          text_color=\"#F2FFFC\",\n",
    "                          box_color=\"#FF0000\"):\n",
    "    # FONT\n",
    "    #https://github.com/agentyzmin/Road-UA-Font/tree/main/Road%20UA/OTF\n",
    "    fontpath = os.path.join(nomeroff_net_dir, \"data/fonts/RoadUA-Medium.otf\")\n",
    "    font = ImageFont.truetype(fontpath, 44)\n",
    "    \n",
    "    number_fontpath = os.path.join(nomeroff_net_dir, \"data/fonts/RoadUA-Medium.otf\")\n",
    "    number_font = ImageFont.truetype(number_fontpath, 44)\n",
    "    \n",
    "    code_fontpath = os.path.join(nomeroff_net_dir, \"data/fonts/RoadUA-Medium.otf\")\n",
    "    code_font = ImageFont.truetype(number_fontpath, 31)\n",
    "\n",
    "    img = img.copy()\n",
    "    img.thumbnail((235, 51))\n",
    "\n",
    "    poly_w = 0\n",
    "    while poly_w < 100:\n",
    "        random_img, ordered_p_fake = get_random_img()\n",
    "        poly_w = distance(ordered_p_fake[0], ordered_p_fake[1])\n",
    "\n",
    "    random_img = random_img.astype(np.uint8)\n",
    "\n",
    "    #print(ordered_p_fake)\n",
    "    random_img_np = get_cv_zone_rgb(random_img, ordered_p_fake)\n",
    "#     print(\"random_img_np\", np.mean(random_img_np[:,:,:3]), np.max(random_img_np[:,:,:3]),\n",
    "#           np.min(random_img_np[:,:,:3]))\n",
    "#     plt.imshow(random_img_np)\n",
    "#     plt.show()\n",
    "    draw = ImageDraw.Draw(img)\n",
    "\n",
    "    numberpalte = random.choice(text_np_variants)\n",
    "    x_left_margin = 0\n",
    "    #print(draw.textsize(numberpalte[:2], code_font))\n",
    "    x_s = 27 + ((200 - (draw.textsize(numberpalte[:2], code_font)[0] + x_left_margin\n",
    "                     + draw.textsize(numberpalte[2:4], number_font)[0] + x_left_margin\n",
    "                     + draw.textsize(numberpalte[4:], font)[0])))/2\n",
    "    \n",
    "    #print(\"x_s\", x_s)\n",
    "    draw.rectangle([(25, 3), (226, 45)], fill=box_color, outline=box_color)\n",
    " \n",
    "    draw.text((x_s, 17), numberpalte[:2], font = code_font, fill = (b, g, r, a))\n",
    "    x_s += draw.textsize(numberpalte[:2], code_font)[0] + x_left_margin\n",
    "\n",
    "    draw.text((x_s, 7), numberpalte[2:4], font = font, fill = (b, g, r, a))\n",
    "    x_s += draw.textsize(numberpalte[2:4], font)[0] + x_left_margin\n",
    "\n",
    "\n",
    "    draw.text((x_s, 7), numberpalte[4:], font = number_font, fill = (b, g, r, a))\n",
    "\n",
    "    img = np.array(img)\n",
    "\n",
    "    #print(\"orig color\", np.mean(img[:,:,:3]), np.max(img[:,:,:3]), np.min(img[:,:,:3]))\n",
    "#     plt.imshow(img)\n",
    "#     plt.show()\n",
    "\n",
    "    #img[:,:,:3] = color_transfer(random_img_np, img[:,:,:3])\n",
    "    # \"speckle\", \"poisson\", \"s&p\",  \"gauss\"\n",
    "    #img[:,:,:3] = noisy(\"gauss\", img[:,:,:3])\n",
    "    #img[:,:,:3] = domain_adoptation(src=img[:,:,:3], trg=random_img_np, freq=1)\n",
    "    #img[:,:,:3] = distribution(img[:,:,:3], cauchy,  np.mean(random_img), np.mean(random_img)+90)\n",
    "\n",
    "#     print(\"color corrected\", np.mean(img[:,:,:3]), np.min(img[:,:,:3]), np.max(img[:,:,:3]))\n",
    "#     plt.imshow(img)\n",
    "#     plt.show()\n",
    "\n",
    "    fake_img = draw_fake(img, random_img, ordered_p_fake)\n",
    "    return fake_img, img, numberpalte, ordered_p_fake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "fac32f1d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "146bc8f1e25f41c9942fd04e37b2c51e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "n = 20_000\n",
    "debug = 0\n",
    "BOX_COLOR = (220, 43, 25) # Red\n",
    "TEXT_COLOR = (250, 250, 250) # White\n",
    "RES_DIR = os.path.join(PATH_TO_DATASET, f\"../../../TextDetector/TransitUaGenerated{n}\")\n",
    "res_dir_img = os.path.join(RES_DIR, \"img\")\n",
    "res_dir_ann = os.path.join(RES_DIR, \"ann\")\n",
    "\n",
    "os.makedirs(res_dir_img, exist_ok=True)\n",
    "os.makedirs(res_dir_ann, exist_ok=True)\n",
    "for i in tqdm.notebook.tqdm(range(n), total=n):\n",
    "    #np.random.shuffle(images_formats)\n",
    "    for image_format in images_formats:\n",
    "        #print(path_to_images_example.format(image_format))\n",
    "        img = Image.open(path_to_images_example.format(image_format)).convert(\"RGBA\")\n",
    "        #print(np.array(img).shape)\n",
    "        gen_img, img_crop, numberplate, np_points = draw_fake_numberplate(img)\n",
    "        #print(numberplate, img.size)\n",
    "        np_img = crop_and_aug_numbeplate(gen_img, np_points)\n",
    "        # WTF? (when some not correct values image backome a one color image )\n",
    "        if np.max(np_img[:,:,0]) - np.min(np_img[:,:,0]) > 50 \\\n",
    "               or np.max(np_img[:,:,1]) - np.min(np_img[:,:,1]) > 50 \\\n",
    "               or np.max(np_img[:,:,2]) - np.min(np_img[:,:,2]) > 50:\n",
    "            if debug:\n",
    "                plt.imshow(np_img)\n",
    "                plt.show()\n",
    "            else:\n",
    "                cv2.imwrite(os.path.join(res_dir_img, f\"{i}_{numberplate}.png\"), np_img[:,:,::-1])\n",
    "                with open(os.path.join(res_dir_ann, f\"{i}_{numberplate}.json\"), \"w\") as fp:\n",
    "                    json.dump({\n",
    "                        \"tags\":[],\n",
    "                        \"objects\":[],\n",
    "                        \"state_id\":\"2\",\n",
    "                        \"region_id\":\"1\",\n",
    "                        \"is_generated\": 1,\n",
    "                        \"size\":{\"width\": np_img.shape[0], \"height\": np_img.shape[1]},\n",
    "                        \"moderation\":{\"isModerated\":1,\"moderatedBy\":\"autogen\",\"predicted\": numberplate},\n",
    "                        \"description\": numberplate,\n",
    "                        \"name\": f\"{i}_{numberplate}\",\n",
    "                        \"count_lines\": \"1\"}, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2258873e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": [
     "import os\n",
     "import sys\n",
     "import random\n",
     "import glob\n",
     "import cv2\n",
     "import json\n",
     "import string\n",
     "import tqdm\n",
     "import numpy as np\n",
     "from imutils.perspective import four_point_transform\n",
     "from skimage import exposure\n",
     "\n",
     "from skimage.io import imread, imshow\n",
     "from skimage import img_as_ubyte\n",
     "from skimage.color import rgb2gray\n",
     "from skimage.exposure import histogram, cumulative_distribution\n",
     "from scipy.stats import cauchy, logistic\n",
     "\n",
     "import warnings\n",
     "import imutils\n",
     "from collections import Counter\n",
     "from collections import Counter\n",
     "from PIL import ImageFont, ImageDraw, Image\n",
     "from matplotlib import pyplot as plt\n",
     "import re\n",
     "import string\n",
     "from faker import Faker\n",
     "import albumentations as A\n",
     "\n",
     "from _paths import nomeroff_net_dir\n",
     "from nomeroff_net.tools.image_processing import get_cv_zone_rgb, distance\n",
     "from nomeroff_net.tools import modelhub\n",
     "from nomeroff_net.tools import modelhub\n",
     "\n",
     "warnings.simplefilter(\"ignore\")\n",
     "\n",
     "def visualize(image):\n",
     "    plt.figure(figsize=(20, 20))\n",
     "    plt.axis('off')\n",
     "    plt.imshow(image)\n",
     "\n",
     "plt.rcParams[\"figure.figsize\"] = (20,20)\n",
     "# auto download latest dataset\n",
     "info = modelhub.download_dataset_for_model(\"yolov8\")\n",
     "PATH_TO_DATASET = info[\"dataset_path\"]\n",
     "ROOT_DIR = PATH_TO_DATASET\n",
     "dataset = \"train\"\n",
     "json_data_path = \"train/via_region_data.json\"\n",
     "\n",
     "images_formats = [\n",
     "    \"eu-ua-2015-custom.png\",\n",
     "]\n",
     "path_to_images_example = os.path.join(nomeroff_net_dir,\n",
     "                                      \"data/dataset/OptionsDetector/numberplate_options_example/test/img/{}\")\n",
     "\n",
     "\n",
     "class FakeCustomNumberplateMaker():\n",
     "    def __init__(self, langs=None, fake_categs=None):\n",
     "        if langs is None:\n",
     "            langs = [\"uk_UA\", \"ru_RU\", \"en\"]\n",
     "        if fake_categs is None:\n",
     "            fake_categs = {\n",
     "                \"email\": 20_000,\n",
     "                \"country\": 5_000,\n",
     "                \"bank\": 5_000,\n",
     "                \"job\": 10_000,\n",
     "                \"large_company\": 10_000,\n",
     "                \"last_name\": 10_000,\n",
     "                \"license_plate\": 10_000,\n",
     "                \"first_name\": 20_000,\n",
     "                \"month_name\": 100,\n",
     "                \"nic_handle\": 5_000,\n",
     "                \"region\": 2_000,\n",
     "                \"url\": 10_000,\n",
     "                \"word\": 20_000,\n",
     "                \"year\": 1_000,\n",
     "            }\n",
     "        self.ukr_eng_mapping = {\n",
     "            \"А\": \"A\",\n",
     "            \"В\": \"B\",\n",
     "            \"Е\": \"E\",\n",
     "            \"І\": \"I\",\n",
     "            \"К\": \"K\",\n",
     "            \"М\": \"M\",\n",
     "            \"Н\": \"H\",\n",
     "            \"О\": \"O\",\n",
     "            \"Р\": \"P\",\n",
     "            \"С\": \"C\",\n",
     "            \"Т\": \"T\",\n",
     "            \"Х\": \"X\",\n",
     "            \"У\": \"Y\"\n",
     "        }\n",
     "        self.eng_alphabet = [\n",
     "            \"A\", \"B\", \"C\", \"D\", \"E\", \"F\", \"G\", \"H\", \"I\", \"J\", \"K\", \"L\", \"M\",\n",
     "            \"N\", \"O\", \"P\", \"Q\", \"R\", \"S\", \"T\", \"U\", \"V\", \"W\", \"X\", \"Y\", \"Z\"\n",
     "        ]\n",
     "        self.ukr_alphabet = [\n",
     "            \"А\", \"Б\", \"В\", \"Г\", \"Ґ\", \"Д\", \"Е\", \"Є\", \"Ж\", \"З\", \"И\", \"І\", \"Ї\",\n",
     "            \"Й\", \"К\", \"Л\", \"М\", \"Н\", \"О\", \"П\", \"Р\", \"С\", \"Т\", \"У\", \"Ф\", \"Х\",\n",
     "            \"Ц\", \"Ч\", \"Ш\", \"Щ\", \"Ь\", \"Ю\", \"Я\"\n",
     "        ]\n",
     "        self.digits = string.digits\n",
     "        self.ru_alphabet = [\n",
     "            \"А\", \"Б\", \"В\", \"Г\", \"Д\", \"Е\", \"Ё\", \"Ж\", \"З\", \"И\", \"Й\", \"К\", \"Л\",\n",
     "            \"М\", \"Н\", \"О\", \"П\", \"Р\", \"С\", \"Т\", \"У\", \"Ф\", \"Х\", \"Ц\", \"Ч\", \"Ш\",\n",
     "            \"Щ\", \"Ъ\", \"Ы\", \"Ь\", \"Э\", \"Ю\", \"Я\"\n",
     "        ]\n",
     "\n",
     "\n",
     "        self.fake = Faker(langs)\n",
     "        self.fake_categs = fake_categs\n",
     "        self.langs = langs\n",
     "\n",
     "    @staticmethod\n",
     "    def split_string(s):\n",
     "        # Розбиваємо рядок по всіх символах, які не є буквами або цифрами\n",
     "        return re.split('[^a-zA-Z0-9а-яА-ЯіІїЇєЄёЁ]+', s)\n",
     "\n",
     "    @staticmethod\n",
     "    def filter_fake_words(fake_worlds):\n",
     "        fake_worlds = [fake_world.upper() for fake_world in fake_worlds]\n",
     "        return [fake_world for fake_world in fake_worlds\n",
     "                if 2<len(fake_world)<9 and 'Э' not in fake_worlds and 'Ы' not in fake_worlds\n",
     "               and 'Ъ' not in fake_worlds and 'Ъ' not in fake_worlds]\n",
     "\n",
     "    @staticmethod\n",
     "    def insert_random_numbers(s, count=1):\n",
     "        \"\"\"\n",
     "        Додає випадкові цифри в рядок на випадкових позиціях.\n",
     "\n",
     "        Parameters:\n",
     "        - s (str): Вихідний рядок.\n",
     "        - count (int): Кількість випадкових цифр, які слід додати.\n",
     "\n",
     "        Returns:\n",
     "        - str: Рядок з вставленими цифрами.\n",
     "        \"\"\"\n",
     "        for _ in range(count):\n",
     "            # Вибір випадкової позиції\n",
     "            position = random.randint(0, len(s))\n",
     "\n",
     "            # Вибір випадкової цифри\n",
     "            digit = str(random.randint(0, 9))\n",
     "\n",
     "            # Вставка цифри на вибрану позицію\n",
     "            s = s[:position] + digit + s[position:]\n",
     "\n",
     "        return s\n",
     "\n",
     "    def normalize_world(self, fake_world):\n",
     "        fake_world = fake_world.upper()\n",
     "        fake_world = \"\".join([self.ukr_eng_mapping.get(letter, letter)\n",
     "                              for letter in fake_world])\n",
     "        if fake_world.isdigit():\n",
     "            pass\n",
     "        elif fake_world.isalpha():\n",
     "            count_num = random.randint(0, min([6, 8-len(fake_world)]))\n",
     "            if count_num != 0:\n",
     "                fake_world = self.insert_random_numbers(fake_world, count=count_num)\n",
     "        return fake_world\n",
     "\n",
     "    def normalize_worlds(self, fake_worlds):\n",
     "        return [self.normalize_world(fake_world) for fake_world in fake_worlds]\n",
     "\n",
     "    def generate_fake_by_categ(self, categ, n):\n",
     "        fakes = []\n",
     "        for _ in range(n):\n",
     "            fake_text = getattr(self.fake, categ)()\n",
     "            fake_worlds = self.split_string(fake_text)\n",
     "            fake_worlds = self.filter_fake_words(fake_worlds)\n",
     "            fake_worlds = self.normalize_worlds(fake_worlds)\n",
     "            fakes.extend(fake_worlds)\n",
     "        return fakes\n",
     "\n",
     "    def __call__(self):\n",
     "        fake_numberplate_texts = []\n",
     "        for categ in self.fake_categs:\n",
     "            n = self.fake_categs[categ]\n",
     "            fakes = self.generate_fake_by_categ(categ, n)\n",
     "            fake_numberplate_texts.extend(fakes)\n",
     "        fake_numberplate_texts = list(set(fake_numberplate_texts))\n",
     "        random.shuffle(fake_numberplate_texts)\n",
     "        return fake_numberplate_texts\n",
     "\n",
     "fake_custom_numberplate_maker = FakeCustomNumberplateMaker()\n",
     "fake_custom_numberplates = fake_custom_numberplate_maker()\n",
     "len(fake_custom_numberplates)\n",
     "\n",
     "res_datasets = {}\n",
     "res_datasets[dataset] = []\n",
     "\n",
     "with open(os.path.join(ROOT_DIR, json_data_path)) as jsonFile:\n",
     "    json_data = json.load(jsonFile)\n",
     "for key in tqdm.tqdm((json_data[\"_via_img_metadata\"])):\n",
     "    metadata = json_data[\"_via_img_metadata\"][key]\n",
     "\n",
     "    # define image_id\n",
     "    image_file_name = metadata[\"filename\"]\n",
     "    image_file_name = os.path.join(ROOT_DIR, dataset, image_file_name)\n",
     "    for region in metadata[\"regions\"]:\n",
     "        if region[\"shape_attributes\"].get(\"all_points_x\", None) is None or region[\"shape_attributes\"].get(\"all_points_y\", None) is None:\n",
     "            continue\n",
     "        np_zone = [(x, y) for x, y in zip(region[\"shape_attributes\"][\"all_points_x\"], region[\"shape_attributes\"][\"all_points_y\"])]\n",
     "        res_datasets[dataset].append([image_file_name, np_zone])\n",
     "\n",
     "def order_points(pts):\n",
     "    # initialzie a list of coordinates that will be ordered\n",
     "    # such that the first entry in the list is the top-left,\n",
     "    # the second entry is the top-right, the third is the\n",
     "    # bottom-right, and the fourth is the bottom-left\n",
     "    rect = np.zeros((4, 2), dtype = \"float32\")\n",
     "    # the top-left point will have the smallest sum, whereas\n",
     "    # the bottom-right point will have the largest sum\n",
     "    s = pts.sum(axis = 1)\n",
     "    rect[0] = pts[np.argmin(s)]\n",
     "    rect[2] = pts[np.argmax(s)]\n",
     "    # now, compute the difference between the points, the\n",
     "    # top-right point will have the smallest difference,\n",
     "    # whereas the bottom-left will have the largest difference\n",
     "    diff = np.diff(pts, axis = 1)\n",
     "    rect[1] = pts[np.argmin(diff)]\n",
     "    rect[3] = pts[np.argmax(diff)]\n",
     "    # return the ordered coordinates\n",
     "    return rect\n",
     "\n",
     "def show_linear_cdf(image, channel, name, ax):\n",
     "    image_intensity = img_as_ubyte(image[:,:,channel])\n",
     "    freq, bins = cumulative_distribution(image_intensity)\n",
     "    target_bins = np.arange(255)\n",
     "    target_freq = np.linspace(0, 1, len(target_bins))\n",
     "    ax.step(bins, freq, c='b', label='Actual CDF')\n",
     "    ax.plot(target_bins, target_freq, c='r', label='Target CDF')\n",
     "    ax.legend()\n",
     "    ax.set_title('{} Channel: Actual vs. '\n",
     "                 'Target Cumulative Distribution'.format(name))\n",
     "\n",
     "def linear_distribution(image, channel):\n",
     "    image_intensity = img_as_ubyte(image[:,:,channel])\n",
     "    freq, bins = cumulative_distribution(image_intensity)\n",
     "    target_bins = np.arange(255)\n",
     "    target_freq = np.linspace(0, 1, len(target_bins))\n",
     "    new_vals = np.interp(freq, target_freq, target_bins)\n",
     "    return new_vals[image_intensity].astype(np.uint8)\n",
     "\n",
     "\n",
     "def individual_channel(image, dist, channel):\n",
     "    im_channel = img_as_ubyte(image[:,:,channel])\n",
     "    freq, bins = cumulative_distribution(im_channel)\n",
     "    new_vals = np.interp(freq, dist.cdf(np.arange(0,256)),\n",
     "                               np.arange(0,256))\n",
     "    return new_vals[im_channel].astype(np.uint8)\n",
     "\n",
     "\n",
     "def distribution(image, function, mean, std):\n",
     "    dist = function(mean, std)\n",
     "    image_intensity = img_as_ubyte(rgb2gray(image))\n",
     "    freq, bins = cumulative_distribution(image_intensity)\n",
     "    red = individual_channel(image, dist, 0)\n",
     "    green = individual_channel(image, dist, 1)\n",
     "    blue = individual_channel(image, dist, 2)\n",
     "    corrected_image = np.dstack((red, green, blue))\n",
     "    return corrected_image\n",
     "\n",
     "\n",
     "def get_random_img():\n",
     "    random_i = random.randint(0, len(res_datasets[dataset]) - 1)\n",
     "    fake_img_path, fake_np_four_points = res_datasets[dataset][random_i]\n",
     "\n",
     "    fake_img = cv2.imread(fake_img_path)[:,:,::-1]\n",
     "    fake_img = np.concatenate((fake_img, 255*np.ones((*fake_img.shape[:2], 1))), axis=2)\n",
     "    ordered_p_fake = order_points(np.array(fake_np_four_points, dtype = \"float32\"))\n",
     "\n",
     "    return fake_img, ordered_p_fake\n",
     "\n",
     "\n",
     "def draw_fake(img, fake_img, ordered_p_fake):\n",
     "\n",
     "    r1, g1, b1 = 20, 20, 20 # Original value\n",
     "    r2, g2, b2 = 20, 20, 20 # Value that we want to replace it with\n",
     "\n",
     "    red, green, blue = img[:,:,0], img[:,:,1], img[:,:,2]\n",
     "    mask = (red < r1) & (green < g1) & (blue < b1)\n",
     "    img[:,:,:3][mask] = [r2, g2, b2]\n",
     "\n",
     "    ordered_p_orig = np.array([(0, 0),\n",
     "                               (img.shape[1], 0),\n",
     "                               (img.shape[1], img.shape[0]),\n",
     "                               (0, img.shape[0])], dtype = \"float32\")\n",
     "\n",
     "\n",
     "    M = cv2.getPerspectiveTransform(ordered_p_orig,\n",
     "                                    ordered_p_fake)\n",
     "    warped = cv2.warpPerspective(img, M, (fake_img.shape[1], fake_img.shape[0]))\n",
     "    cntrs = ordered_p_fake.reshape(1, ordered_p_fake.shape[0], ordered_p_fake.shape[1]).astype(np.int32)\n",
     "\n",
     "    #print(\"warped\", img.shape, img[:,:, 0].max(), img[:,:, 1].max(), img[:,:, 2].max())\n",
     "    #print(\"warped\", img.shape, img[:,:, 0].min(), img[:,:, 1].min(), img[:,:, 2].min())\n",
     "\n",
     "    stencil = np.zeros(warped.shape).astype(warped.dtype)\n",
     "    contours = cntrs\n",
     "\n",
     "    cv2.fillPoly(stencil, contours, [255, 255, 255])\n",
     "    np_mask = cv2.bitwise_and(warped, stencil)\n",
     "\n",
     "    overlay_img1 = np.ones(fake_img.shape, np.uint8)*255\n",
     "\n",
     "    rows, cols, channels = np_mask.shape\n",
     "    overlay_img1[:, :] = warped\n",
     "    img2gray = cv2.cvtColor(overlay_img1, cv2.COLOR_BGR2GRAY)\n",
     "\n",
     "    ret, mask = cv2.threshold(img2gray, 1, 255, cv2.THRESH_BINARY)\n",
     "\n",
     "    mask_inv = cv2.bitwise_not(mask)\n",
     "\n",
     "    fake_img = fake_img.astype(np.uint8)\n",
     "    temp1 = cv2.bitwise_and(fake_img, fake_img, mask = mask_inv)\n",
     "    temp2 = cv2.bitwise_and(overlay_img1, overlay_img1, mask = mask)\n",
     "\n",
     "    temp1 = temp1.astype(np.uint8)\n",
     "    fake_np_img = cv2.add(temp1, temp2)\n",
     "    return fake_np_img\n",
     "\n",
     "\n",
     "def domain_adoptation(src, trg, freq):\n",
     "\n",
     "    \"\"\"\n",
     "    Parameters:\n",
     "    src - source image, which style has to be changed\n",
     "    trg - target image, which low-frequency domain will be adopted\n",
     "    freq - number of frequencies to be used\n",
     "\n",
     "    Returns:\n",
     "    result - np.array based on srs image (shape and high frequencies)\n",
     "         with low frequencies of the target image\n",
     "    \"\"\"\n",
     "\n",
     "    result = np.zeros((src.shape[0],src.shape[1],src.shape[2]))\n",
     "\n",
     "    for i in range(src.shape[2]):\n",
     "        trg_fft = np.fft.fft2(trg[:,:,i])\n",
     "        src_fft = np.fft.fft2(src[:,:,i])\n",
     "\n",
     "        trg_fft_shift = np.fft.fftshift(trg_fft)\n",
     "        src_fft_shift = np.fft.fftshift(src_fft)\n",
     "\n",
     "        src_fft_shift[src.shape[0]//2-freq:src.shape[0]//2+freq,\n",
     "                         src.shape[1]//2-freq:src.shape[1]//2+freq] = \\\n",
     "            trg_fft_shift[trg.shape[0]//2-freq:trg.shape[0]//2+freq,\n",
     "                           trg.shape[1]//2-freq:trg.shape[1]//2+freq]\n",
     "\n",
     "        src_ifft_shift = np.fft.ifftshift(src_fft_shift)\n",
     "\n",
     "        result[:,:,i] = np.fft.ifft2(src_ifft_shift)\n",
     "        result[:,:,i] = np.abs(result[:,:,i])\n",
     "\n",
     "    result = np.float32(result)\n",
     "    result = cv2.cvtColor(result, cv2.COLOR_BGR2RGB)\n",
     "    result = cv2.normalize(result,None,0,1,cv2.NORM_MINMAX)\n",
     "\n",
     "    return result\n",
     "\n",
     "def color_transfer(source, target):\n",
     "    source = cv2.resize(source, (target.shape[1], target.shape[0]))\n",
     "    # convert the images from the RGB to L*ab* color space, being\n",
     "    # sure to utilizing the floating point data type (note: OpenCV\n",
     "    # expects floats to be 32-bit, so use that instead of 64-bit)\n",
     "    source = cv2.cvtColor(source, cv2.COLOR_BGR2LAB).astype(\"float32\")\n",
     "    target = cv2.cvtColor(target, cv2.COLOR_BGR2LAB).astype(\"float32\")\n",
     "    # compute color statistics for the source and target images\n",
     "    (lMeanSrc, lStdSrc, aMeanSrc, aStdSrc, bMeanSrc, bStdSrc) = image_stats(source)\n",
     "    (lMeanTar, lStdTar, aMeanTar, aStdTar, bMeanTar, bStdTar) = image_stats(target)\n",
     "    # subtract the means from the target image\n",
     "    (l, a, b) = cv2.split(target)\n",
     "    l -= lMeanTar\n",
     "    a -= aMeanTar\n",
     "    b -= bMeanTar\n",
     "    # scale by the standard deviations\n",
     "    l = (lStdTar / lStdSrc) * l\n",
     "    a = (aStdTar / aStdSrc) * a\n",
     "    b = (bStdTar / bStdSrc) * b\n",
     "    # add in the source mean\n",
     "    l += lMeanSrc\n",
     "    a += aMeanSrc\n",
     "    b += bMeanSrc\n",
     "    # clip the pixel intensities to [0, 255] if they fall outside\n",
     "    # this range\n",
     "    l = np.clip(l, 0, 255)\n",
     "    a = np.clip(a, 0, 255)\n",
     "    b = np.clip(b, 0, 255)\n",
     "    # merge the channels together and convert back to the RGB color\n",
     "    # space, being sure to utilize the 8-bit unsigned integer data\n",
     "    # type\n",
     "    transfer = cv2.merge([l, a, b])\n",
     "    transfer = cv2.cvtColor(transfer.astype(\"uint8\"), cv2.COLOR_LAB2BGR)\n",
     "\n",
     "    # return the color transferred image\n",
     "    return transfer\n",
     "\n",
     "\n",
     "def image_stats(image):\n",
     "    # compute the mean and standard deviation of each channel\n",
     "    (l, a, b) = cv2.split(image)\n",
     "    (lMean, lStd) = (l.mean(), l.std())\n",
     "    (aMean, aStd) = (a.mean(), a.std())\n",
     "    (bMean, bStd) = (b.mean(), b.std())\n",
     "    # return the color statistics\n",
     "    return (lMean, lStd, aMean, aStd, bMean, bStd)\n",
     "\n",
     "\n",
     "BOX_COLOR = (255, 0, 0) # Red\n",
     "TEXT_COLOR = (255, 255, 255) # White\n",
     "\n",
     "\n",
     "def visualize_bbox(img, bbox, color=BOX_COLOR, thickness=2, **kwargs):\n",
     "    x_min, y_min, w, h = bbox\n",
     "    x_min, x_max, y_min, y_max = int(x_min), int(x_min + w), int(y_min), int(y_min + h)\n",
     "    cv2.rectangle(img, (x_min, y_min), (x_max, y_max), color=color, thickness=thickness)\n",
     "    return img\n",
     "\n",
     "def visualize_titles(img, bbox, title, color=BOX_COLOR, thickness=2, font_thickness = 2, font_scale=0.35, **kwargs):\n",
     "    x_min, y_min, w, h = bbox\n",
     "    x_min, x_max, y_min, y_max = int(x_min), int(x_min + w), int(y_min), int(y_min + h)\n",
     "    ((text_width, text_height), _) = cv2.getTextSize(title, cv2.FONT_HERSHEY_SIMPLEX, font_scale, font_thickness)\n",
     "    cv2.rectangle(img, (x_min, y_min - int(1.3 * text_height)), (x_min + text_width, y_min), BOX_COLOR, -1)\n",
     "    cv2.putText(img, title, (x_min, y_min - int(0.3 * text_height)), cv2.FONT_HERSHEY_SIMPLEX, font_scale, TEXT_COLOR,\n",
     "                font_thickness, lineType=cv2.LINE_AA)\n",
     "    return img\n",
     "\n",
     "\n",
     "def augment_and_show(aug, image, filename=None,\n",
     "                     font_scale_orig=0.35, font_scale_aug=0.35, show=True, **kwargs):\n",
     "\n",
     "    augmented = aug(image=image)\n",
     "\n",
     "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
     "    image_aug = cv2.cvtColor(augmented['image'], cv2.COLOR_BGR2RGB)\n",
     "\n",
     "    if show:\n",
     "        f, ax = plt.subplots(1, 2, figsize=(16, 8))\n",
     "        ax[0].imshow(image)\n",
     "        ax[0].set_title('Original image')\n",
     "        ax[1].imshow(image_aug)\n",
     "        ax[1].set_title('Augmented image')\n",
     "        f.tight_layout()\n",
     "\n",
     "        if filename is not None:\n",
     "            f.savefig(filename)\n",
     "\n",
     "    return augmented['image']\n",
     "\n",
     "def find_in_dir(dirname):\n",
     "    return [os.path.join(dirname, fname) for fname in sorted(os.listdir(dirname))]\n",
     "\n",
     "\n",
     "def crop_and_aug_numbeplate(np_img, ordered_p_fake):\n",
     "    l = np.random.uniform(0.01, 0.06)\n",
     "    random_r_crop = np.random.uniform(0.06, 0.1)\n",
     "    random_l_crop = np.random.uniform(0.01, 0.08)\n",
     "    np_img = np_img[:,:,:3].astype(np.uint8)\n",
     "    #print(np_img.shape)\n",
     "    # img_np = cv2.polylines(np_img, [ordered_p_fake.reshape((-1, 1, 2)).astype(np.int32)], True, (255, 0, 255), 2)\n",
     "\n",
     "    d_crop_l = (distance(ordered_p_fake[0], ordered_p_fake[1])+distance(ordered_p_fake[3], ordered_p_fake[3]))/2*random_l_crop\n",
     "    d_crop_r = (distance(ordered_p_fake[0], ordered_p_fake[1])+distance(ordered_p_fake[3], ordered_p_fake[3]))/2*random_r_crop\n",
     "    d2 = (distance(ordered_p_fake[1], ordered_p_fake[2])+distance(ordered_p_fake[3], ordered_p_fake[0]))/2*l\n",
     "    ordered_p_fake[0,0] += d_crop_l\n",
     "    ordered_p_fake[1,0] -= d_crop_r\n",
     "    ordered_p_fake[2,0] -= d_crop_r\n",
     "    ordered_p_fake[3,0] += d_crop_l\n",
     "\n",
     "    ordered_p_fake[1,1] -= d2\n",
     "    ordered_p_fake[2,1] += d2\n",
     "    ordered_p_fake[0,1] -= d2\n",
     "    ordered_p_fake[3,1] += d2\n",
     "    img_np = get_cv_zone_rgb(np_img, ordered_p_fake)\n",
     "\n",
     "    light = A.Compose([\n",
     "        A.RandomBrightnessContrast(p=1),\n",
     "        A.RandomGamma(p=1),\n",
     "        A.CLAHE(p=1),\n",
     "        A.Blur(),\n",
     "        A.GaussNoise(),\n",
     "        A.ShiftScaleRotate(shift_limit=0.01, scale_limit=0.01, rotate_limit=2, p=.75),\n",
     "    ], p=5)\n",
     "\n",
     "\n",
     "    # img_np = cv2.polylines(np_img, [ordered_p_fake.reshape((-1, 1, 2)).astype(np.int32)], True, (0, 255, 255), 2)\n",
     "    return augment_and_show(light, img_np, show=False)\n",
     "\n",
     "def draw_fake_numberplate(img,\n",
     "                          b: int = 20, g: int = 20, r: int = 20, a: int = 255,\n",
     "                          draw_text=True,\n",
     "                          draw_numbers=True,\n",
     "                          text_color=\"#143800\"):\n",
     "    # FONT\n",
     "    fontpath = os.path.join(nomeroff_net_dir, \"data/fonts/Eu_ua_custom_np-Regular.otf\")\n",
     "    font = ImageFont.truetype(fontpath, 43)\n",
     "    number_fontpath = os.path.join(nomeroff_net_dir, \"data/fonts/Eu_ua_custom_np-Regular.otf\")\n",
     "    number_font = ImageFont.truetype(number_fontpath, 18)\n",
     "\n",
     "    img = img.copy()\n",
     "    img.thumbnail((235, 51))\n",
     "\n",
     "    poly_w = 0\n",
     "    while poly_w < 100:\n",
     "        random_img, ordered_p_fake = get_random_img()\n",
     "        poly_w = distance(ordered_p_fake[0], ordered_p_fake[1])\n",
     "\n",
     "    random_img = random_img.astype(np.uint8)\n",
     "\n",
     "    #print(ordered_p_fake)\n",
     "    random_img_np = get_cv_zone_rgb(random_img, ordered_p_fake)\n",
     "#     print(\"random_img_np\", np.mean(random_img_np[:,:,:3]), np.max(random_img_np[:,:,:3]),\n",
     "#           np.min(random_img_np[:,:,:3]))\n",
     "#     plt.imshow(random_img_np)\n",
     "#     plt.show()\n",
     "    draw = ImageDraw.Draw(img)\n",
     "\n",
     "    numberpalte = random.choice(fake_custom_numberplates)\n",
     "    seria = random.choice(random_series)\n",
     "    #print(numberpalte, seria)\n",
     "    x_left_margin = 6\n",
     "    x_s = 27 + ((150 - (draw.textsize(numberpalte[:2], font)[0] + x_left_margin\n",
     "                     + draw.textsize(numberpalte[2:6], number_font)[0] + x_left_margin\n",
     "                     + draw.textsize(numberpalte[6:], font)[0])))/2\n",
     "\n",
     "    #print(\"x_s\", x_s)\n",
     "    draw.rectangle([(28, 5), (226, 45)], fill =\"white\", outline =\"white\")\n",
     "    draw.rectangle([(5, 30), (25, 45)], fill =\"white\", outline =\"white\")\n",
     "    draw.text((x_s, 8), numberpalte, font = font, fill = (r, g, b, a))\n",
     "    draw.text((5, (45+5+10)/2), seria, font = number_font, fill = (r, g, b, a))\n",
     "\n",
     "    img = np.array(img)\n",
     "\n",
     "#     print(\"orig color\", np.mean(img[:,:,:3]), np.max(img[:,:,:3]), np.min(img[:,:,:3]))\n",
     "#     plt.imshow(img)\n",
     "#     plt.show()\n",
     "\n",
     "    img[:,:,:3] = color_transfer(random_img_np, img[:,:,:3])\n",
     "    # \"speckle\", \"poisson\", \"s&p\",  \"gauss\"\n",
     "    #img[:,:,:3] = noisy(\"gauss\", img[:,:,:3])\n",
     "    #img[:,:,:3] = domain_adoptation(src=img[:,:,:3], trg=random_img_np, freq=1)\n",
     "    #img[:,:,:3] = distribution(img[:,:,:3], cauchy,  np.mean(random_img), np.mean(random_img)+90)\n",
     "\n",
     "#     print(\"color corrected\", np.mean(img[:,:,:3]), np.min(img[:,:,:3]), np.max(img[:,:,:3]))\n",
     "#     plt.imshow(img)\n",
     "#     plt.show()\n",
     "\n",
     "    fake_img = draw_fake(img, random_img, ordered_p_fake)\n",
     "    return fake_img, img, numberpalte, ordered_p_fake\n",
     "\n",
     "\n",
     "n = 100_000\n",
     "debug = 0\n",
     "RES_DIR = os.path.join(PATH_TO_DATASET, f\"../../../TextDetector/EuUaCustomGenerated{n}\")\n",
     "res_dir_img = os.path.join(RES_DIR, \"img\")\n",
     "res_dir_ann = os.path.join(RES_DIR, \"ann\")\n",
     "\n",
     "os.makedirs(res_dir_img, exist_ok=True)\n",
     "os.makedirs(res_dir_ann, exist_ok=True)\n",
     "for i in tqdm.notebook.tqdm(range(n), total=n):\n",
     "    #np.random.shuffle(images_formats)\n",
     "    for image_format in images_formats:\n",
     "        #print(path_to_images_example.format(image_format))\n",
     "        img = Image.open(path_to_images_example.format(image_format)).convert(\"RGBA\")\n",
     "        #print(np.array(img).shape)\n",
     "        gen_img, img_crop, numberplate, np_points = draw_fake_numberplate(img)\n",
     "        #print(numberplate, img.size)\n",
     "        np_img = crop_and_aug_numbeplate(gen_img, np_points)\n",
     "        # WTF? (when some not correct values image backome a one color image )\n",
     "        if np.max(np_img[:,:,0]) - np.min(np_img[:,:,0]) > 50 \\\n",
     "               or np.max(np_img[:,:,1]) - np.min(np_img[:,:,1]) > 50 \\\n",
     "               or np.max(np_img[:,:,2]) - np.min(np_img[:,:,2]) > 50:\n",
     "            if debug:\n",
     "                plt.imshow(np_img)\n",
     "                plt.show()\n",
     "            else:\n",
     "                cv2.imwrite(os.path.join(res_dir_img, f\"{i}_{numberplate}.png\"), np_img[:,:,::-1])\n",
     "                with open(os.path.join(res_dir_ann, f\"{i}_{numberplate}.json\"), \"w\") as fp:\n",
     "                    json.dump({\n",
     "                        \"tags\":[],\n",
     "                        \"objects\":[],\n",
     "                        \"state_id\":\"2\",\n",
     "                        \"region_id\":\"1\",\n",
     "                        \"is_generated\": 1,\n",
     "                        \"size\":{\"width\": np_img.shape[0], \"height\": np_img.shape[1]},\n",
     "                        \"moderation\":{\"isModerated\":1,\"moderatedBy\":\"autogen\",\"predicted\": numberplate},\n",
     "                        \"description\": numberplate,\n",
     "                        \"name\": f\"{i}_{numberplate}\",\n",
     "                        \"count_lines\": \"1\"}, fp)\n"
    ]
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
